{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling \n",
    "import pandas as pd \n",
    "\n",
    "# Deep learning \n",
    "import tensorflow as tf\n",
    "import keras \n",
    "\n",
    "# Array math \n",
    "import numpy as np\n",
    "\n",
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Mean scaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Loading the memory profile extension\n",
    "from memory_profiler import profile\n",
    "import sys \n",
    "\n",
    "# Ploting \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iteration tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Metrics \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Importing the feature engineering functions \n",
    "from utils import distance_calculation, create_date_vars, create_dummy\n",
    "\n",
    "# Training on CPU\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/train.csv', chunksize=512)\n",
    "\n",
    "# Defining the number of chunks to read \n",
    "n_chunks = 1000\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "for i, chunk in tqdm(enumerate(d)):\n",
    "    if i == n_chunks:\n",
    "        break\n",
    "    df = pd.concat([df, chunk], axis=0)\n",
    "\n",
    "# Removing the negative fare_amount\n",
    "df = df[df['fare_amount'] > 0].copy()\n",
    "\n",
    "# Dropping missing rows\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# reseting the index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Shape of the data: {df.shape}\")\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the size of the object in memory\n",
    "print(f\"The object takes: {sys.getsizeof(df) / 10**6} MB in memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering \n",
    "\n",
    "## Date variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_date_vars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables\n",
    "\n",
    "The features that will be one-hot encoded: \n",
    "\n",
    "* pickup_dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dummy var list \n",
    "dummy_features = [\n",
    "    'pickup_dayofweek'\n",
    "]\n",
    "\n",
    "# Creating the dummy varsW\n",
    "df, new_features = create_dummy(df, dummy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance of travel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = distance_calculation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y=df['fare_amount'], x=df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('passenger_count')['fare_amount'].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\n",
    "       'pickup_dayofweek_1', \n",
    "       'pickup_dayofweek_2', \n",
    "       'pickup_dayofweek_3',\n",
    "       'pickup_dayofweek_4', \n",
    "       'pickup_dayofweek_5', \n",
    "       'pickup_dayofweek_6'\n",
    "       ])['fare_amount'].mean().plot(kind='bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('pickup_hour')['fare_amount'].mean().plot(kind='bar', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final feature list and the ft engineering pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the final feature list \n",
    "numeric_features = [\n",
    "    'distance',\n",
    "    'passenger_count', \n",
    "    'pickup_hour_sin',\n",
    "    'pickup_hour_cos',\n",
    "    'pickup_dayofyear_sin',\n",
    "    'pickup_dayofyear_cos',\n",
    "]\n",
    "\n",
    "# Defining the target variable\n",
    "target = 'fare_amount'\n",
    "\n",
    "# Defining the ft engineering pipeline \n",
    "def ft_engineering_pipeline(\n",
    "    df, \n",
    "    numeric_features, \n",
    "    dummy_features,\n",
    "    target):\n",
    "    \"\"\"\n",
    "    Applies the feature engineering pipeline to the data\n",
    "    \"\"\"\n",
    "    # Creating the date variables\n",
    "    df = create_date_vars(df)\n",
    "\n",
    "    # Creating the dummy variables\n",
    "    df, new_features = create_dummy(df, dummy_features)\n",
    "\n",
    "    # Appending the distance\n",
    "    df = distance_calculation(df) \n",
    "\n",
    "    # Appending the new features to the numeric features\n",
    "    final_features = numeric_features + new_features\n",
    "\n",
    "    # Creating the x matrix \n",
    "    x = df[final_features].values\n",
    "\n",
    "    # Creating the y vector\n",
    "    y = df[target].values\n",
    "\n",
    "    # Mean max scaling the y matrix \n",
    "    y = y.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    y = scaler.fit_transform(y)\n",
    "\n",
    "    # Returning the x and y matrices\n",
    "    return x, y, final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the input for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, features = ft_engineering_pipeline(df, numeric_features, dummy_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of x: {x.shape} | Shape of y: {y.shape}\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the batch size and number of epochs \n",
    "batch_size = 512\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model function \n",
    "def train(x, y, epochs: int = 10, batch_size: int = 128): \n",
    "    # Defining a simple feed forward network \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(x.shape[1],)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error']\n",
    "    )\n",
    "\n",
    "    # Fitting the model\n",
    "    history = model.fit(x, y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Returning the model\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxilary plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAM usage by the whole dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = [\n",
    "    10, \n",
    "    100, \n",
    "    1000,\n",
    "    2000,\n",
    "    5000,\n",
    "    10000,\n",
    "    20000,\n",
    "    54000\n",
    "]\n",
    "\n",
    "ram_usage = [\n",
    "    490,\n",
    "    516,\n",
    "    772,\n",
    "    1117,\n",
    "    1304,\n",
    "    2554,\n",
    "    5252,\n",
    "    12000\n",
    "]\n",
    "\n",
    "# Ploting the relationship\n",
    "plt.figure(figsize=(13, 8))\n",
    "plt.plot(nrows, ram_usage, '-o')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of rows in the training dataset (thousands)')\n",
    "plt.ylabel('RAM usage (MB)')\n",
    "plt.title('RAM usage vs number of rows in the training dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cuda_gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1843498fe16f59076ae8a859587e2a2b45b21ed510245a5df4c4791774183e51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
